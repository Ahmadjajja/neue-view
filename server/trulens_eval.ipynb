{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BDp1ICdFn6wK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "oai_client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "K0kcEYtGn6wS"
      },
      "source": [
        "Add the university_info to the embedding database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZLfmgyFn6wV"
      },
      "source": [
        "## Building RAG Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BMadAHXun6wV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import Tru\n",
        "from trulens_eval.tru_custom_app import instrument\n",
        "tru = Tru()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import random\n",
        "# queries = [[random.random() for _ in range(128)] for _ in range(2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# index.query(\n",
        "#     queries=queries,\n",
        "#     top_k = 3,\n",
        "#     include_values = True,\n",
        "#     include_metadata = True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkqXa1lun6wW"
      },
      "outputs": [],
      "source": [
        "class RAG_from_scratch:\n",
        "    @instrument\n",
        "    def retrieve(self, query: str) -> list:\n",
        "        \"\"\"\n",
        "        Retrieve relevant text from vector store.\n",
        "        \"\"\"\n",
        "        \n",
        "        results = index.query(\n",
        "        queries = query,\n",
        "        top_k = 3,\n",
        "        # include_values = True,\n",
        "        # include_metadata = True\n",
        "    )\n",
        "        return results['documents'][0]\n",
        "\n",
        "    @instrument\n",
        "    def generate_completion(self, query: str, context_str: list) -> str:\n",
        "        \"\"\"\n",
        "        Generate answer from context.\n",
        "        \"\"\"\n",
        "        completion = oai_client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0,\n",
        "        messages=\n",
        "        [\n",
        "            {\"role\": \"user\",\n",
        "            \"content\":\n",
        "            f\"We have provided context information below. \\n\"\n",
        "            f\"---------------------\\n\"\n",
        "            f\"{context_str}\"\n",
        "            f\"\\n---------------------\\n\"\n",
        "            f\"Given this information, please answer the question: {query}\"\n",
        "            }\n",
        "        ]\n",
        "        ).choices[0].message.content\n",
        "        return completion\n",
        "\n",
        "    @instrument\n",
        "    def query(self, query: str) -> str:\n",
        "        context_str = self.retrieve(query)\n",
        "        completion = self.generate_completion(query, context_str)\n",
        "        return completion\n",
        "\n",
        "rag = RAG_from_scratch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM3I2zQen6wZ"
      },
      "source": [
        "## Setting up TruLens Eval Feedback Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J4KK1PP7n6wa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
            "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Answer Relevance, input prompt will be set to __record__.app.retrieve.args.query .\n",
            "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "âœ… In Context Relevance, input question will be set to __record__.app.retrieve.args.query .\n",
            "âœ… In Context Relevance, input statement will be set to __record__.app.retrieve.rets.collect() .\n"
          ]
        }
      ],
      "source": [
        "from trulens_eval import Feedback, Select\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Initialize provider class\n",
        "fopenai = fOpenAI()\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=fopenai)\n",
        "\n",
        "# Define a groundedness feedback function\n",
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")\n",
        "\n",
        "# Question/answer relevance between overall question and answer.\n",
        "f_qa_relevance = (\n",
        "    Feedback(fopenai.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on_output()\n",
        ")\n",
        "\n",
        "# Question/statement relevance between question and each context chunk.\n",
        "f_context_relevance = (\n",
        "    Feedback(fopenai.qs_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
        "    .on(Select.RecordCalls.retrieve.args.query)\n",
        "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
        "    .aggregate(np.mean)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Aw8TeMn6wb"
      },
      "source": [
        "## Construct RAG with TruCustomApp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJECjvv3n6wc"
      },
      "outputs": [],
      "source": [
        "from trulens_eval import TruCustomApp\n",
        "tru_rag = TruCustomApp(rag,\n",
        "    app_id = 'RAG v1',\n",
        "    feedbacks = [f_groundedness, f_qa_relevance, f_context_relevance])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IOVrKmyn6wc"
      },
      "source": [
        "## Run the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISwAKn7Cn6wd"
      },
      "outputs": [],
      "source": [
        "with tru_rag as recording:\n",
        "    rag.query(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoyCaAyxn6wd"
      },
      "outputs": [],
      "source": [
        "tru.get_leaderboard(app_ids=[\"RAG v1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7rfW64Nn6wd"
      },
      "outputs": [],
      "source": [
        "tru.run_dashboard()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "trulens18_release",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
